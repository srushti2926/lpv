{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eLuI5PHE_wcr",
        "outputId": "9c40812d-6d8d-459b-a7cc-158279741ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-04 16:10:33--  https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.59.88.207, 23.59.88.195\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.59.88.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4336730777 (4.0G) [application/octet-stream]\n",
            "Saving to: â€˜cuda_11.8.0_520.61.05_linux.runâ€™\n",
            "\n",
            "cuda_11.8.0_520.61. 100%[===================>]   4.04G   173MB/s    in 33s     \n",
            "\n",
            "2025-05-04 16:11:06 (127 MB/s) - â€˜cuda_11.8.0_520.61.05_linux.runâ€™ saved [4336730777/4336730777]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
        "!chmod +x cuda_11.8.0_520.61.05_linux.run\n",
        "!./cuda_11.8.0_520.61.05_linux.run --silent --toolkit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_fixed.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 4\n",
        "#define MATRIX_SIZE 4\n",
        "\n",
        "__global__ void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void multiply(int* A, int* B, int* C, int size) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "    if (row < size && col < size) {\n",
        "        for (int i = 0; i < size; ++i) {\n",
        "            sum += A[row * size + i] * B[i * size + col];\n",
        "        }\n",
        "        C[row * size + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printVector(const char* name, int* vec, int size) {\n",
        "    printf(\"%s: \", name);\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        printf(\"%d \", vec[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "void printMatrix(const char* name, int* mat, int size) {\n",
        "    printf(\"%s:\\n\", name);\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        for (int j = 0; j < size; ++j) {\n",
        "            printf(\"%d \", mat[i * size + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int A[N], B[N], C[N];\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        A[i] = rand() % 10;\n",
        "        B[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * sizeof(int));\n",
        "    cudaMalloc(&d_B, N * sizeof(int));\n",
        "    cudaMalloc(&d_C, N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_A, A, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    add<<<1, N>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) printf(\"Add Kernel Error: %s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "    cudaMemcpy(C, d_C, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printVector(\"Vector A\", A, N);\n",
        "    printVector(\"Vector B\", B, N);\n",
        "    printVector(\"Addition\", C, N);\n",
        "\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    int size = MATRIX_SIZE;\n",
        "    int elements = size * size;\n",
        "    int D[elements], E[elements], F[elements];\n",
        "    for (int i = 0; i < elements; ++i) {\n",
        "        D[i] = rand() % 10;\n",
        "        E[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    int *d_D, *d_E, *d_F;\n",
        "    cudaMalloc(&d_D, elements * sizeof(int));\n",
        "    cudaMalloc(&d_E, elements * sizeof(int));\n",
        "    cudaMalloc(&d_F, elements * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_D, D, elements * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_E, E, elements * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(2, 2);\n",
        "    dim3 blocksPerGrid((size + 1)/2, (size + 1)/2);\n",
        "\n",
        "    multiply<<<blocksPerGrid, threadsPerBlock>>>(d_D, d_E, d_F, size);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) printf(\"Multiply Kernel Error: %s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "    cudaMemcpy(F, d_F, elements * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printMatrix(\"Matrix D\", D, size);\n",
        "    printMatrix(\"Matrix E\", E, size);\n",
        "    printMatrix(\"Multiplication\", F, size);\n",
        "\n",
        "    cudaFree(d_D); cudaFree(d_E); cudaFree(d_F);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2ICxkXe7BCZF",
        "outputId": "cde7ff0b-fbb3-4746-ad86-24477f9e7780"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_fixed.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cuda_fixed.cu -o cuda_fixed\n",
        "!./cuda_fixed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aRtrLVc8Cvyc",
        "outputId": "202619dd-1367-4487-be60-0915cd027bc5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 7 3 6 \n",
            "Vector B: 6 5 5 2 \n",
            "Addition: 9 12 8 8 \n",
            "Matrix D:\n",
            "9 2 0 3 \n",
            "0 2 1 7 \n",
            "2 2 7 9 \n",
            "2 9 3 1 \n",
            "Matrix E:\n",
            "1 7 9 6 \n",
            "6 6 8 9 \n",
            "0 3 5 2 \n",
            "8 7 6 2 \n",
            "Multiplication:\n",
            "45 96 115 78 \n",
            "68 64 63 34 \n",
            "86 110 123 62 \n",
            "64 84 111 101 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ” Step 1: Enable GPU\n",
        "Go to:\n",
        "\n",
        "Runtime > Change Runtime Type > Select GPU > Click Save\n",
        "\n",
        "ðŸ“¦ Step 2: Install CUDA (with nvcc)\n",
        "Paste this into a Colab cell and run it:\n",
        "\n",
        "bash\n",
        "Copy\n",
        "Edit\n",
        "# Download and install CUDA 11.8\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
        "!chmod +x cuda_11.8.0_520.61.05_linux.run\n",
        "!./cuda_11.8.0_520.61.05_linux.run --silent --toolkit\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/local/cuda-11.8/bin:' + os.environ['PATH']\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.8/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "\n",
        "# Confirm installation\n",
        "!nvcc --version\n",
        "ðŸ§  Step 3: Paste and Compile Your CUDA Program\n",
        "Save code:\n",
        "bash\n",
        "Copy\n",
        "Edit\n",
        "%%writefile cuda_fixed.cu\n",
        "# Paste the fixed CUDA code I gave you earlier\n",
        "Compile and run:\n",
        "bash\n",
        "Copy\n",
        "Edit\n",
        "!nvcc cuda_fixed.cu -o cuda_fixed\n",
        "!./cuda_fixed\n"
      ],
      "metadata": {
        "id": "O56Nuv9tGk2C"
      }
    }
  ]
}